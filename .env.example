bot_token=12345...:...
adminlist=[1810772]
blacklist=[]
whitelist=[1810772, -123456789010]
ignore_mode=both
active_modules=["sd", "tts", "admin"]
tts_path=/Users/user/tts_provider/models
tts_voices=[]
tts_mode=remote
tts_replacements={"key": "value", "key2": "value2"}
tts_credits="TTS models trained by "
tts_ffmpeg_path=/Users/user/Applications/ffmpeg
tts_queue_size_per_user=2
tts_host=http://localhost:7077
sd_host=http://localhost:7860
sd_max_steps=40
sd_max_resolution=1280
sd_available_samplers=["Euler a", "Euler", "Heun", "DPM++ 2M", "DPM++ 2S a"]
sd_extra_prompt = "a high quality image of {prompt}, 8k, masterpiece, detailed, accurate proportions"
sd_extra_negative_prompt = "(worst quality:1.2), (lowres), deepfried, watermark, (blurry), jpeg noise, unsharp, deformed, {negative_prompt}"
sd_default_sampler = "Euler a"
sd_default_n_iter = 1
sd_default_width = 512
sd_default_height = 512
sd_default_tti_steps = 22
sd_default_tti_cfg_scale = 0
sd_default_iti_cfg_scale = 8
sd_default_iti_steps = 30
sd_default_iti_denoising_strength = 0.58
sd_available_loras=[]
sd_lora_custom_activations={"keyword": "trigger word <lora:lora_name:1>"}
sd_only_admins_can_change_models=False
sd_queue_size_per_user=5
apply_mps_fixes=True
llm_queue_size_per_user=2
llm_active_model_type=llama_hf
llm_assistant_chronicler=alpaca
llm_character=characters.llama_chat_default
llm_paths='{
  "path_to_hf_llama":"/Users/user/LLaMA/hf-llama",
  "path_to_llama_code":"/Users/user/LLaMA/llama-mps/", 
  "path_to_llama_weights":"/Users/user/LLaMA/7B/",
  "path_to_llama_tokenizer":"/Users/user/LLaMA/tokenizer.model",
  "path_to_llama_adapter":"/Users/LLaMA/LLaMA-Adapter/llama_adapter_len10_layer30_release.pth",
  "path_to_llama_lora":"/Users/user/LLaMA/alpaca-lora/models/aplaca-lora-7b",
  "path_to_llama_cpp_weights":"/Users/user/LLaMA/llama.cpp/ggml-vicuna-7b-1.1-q4_2.bin",
  "path_to_gptj_weights":"/Users/user/gpt-j/GPT-J-6B_model",
  "path_to_cerebras_weights":"/Users/user/Cerebras-GPT-1.3B",
  "path_to_gpt2_weights":"/Users/user/ru-gpt3-telegram-bot/rugpt3large_based_on_gpt2",
  "path_to_minchatgpt_code":"/Users/user/minChatGPT/src",
  "path_to_mlc_chatbot_code":"/Users/user/LLaMA/mlc-llm/mlc-chatbot/",
  "path_to_mlc_pb_home_dir":"/Users/user/LLaMA/mlc-llm/",
  "path_to_mlc_pb_binary_dir":""
}'
llm_history_grouping=chat
llm_max_history_items=10
llm_generation_cfg_override={}
llm_assistant_cfg_override={"early_stopping": true}
llm_assistant_use_in_chat_mode=False
llm_force_assistant_for_unsupported_models=False
llm_max_tokens=64
llm_max_assistant_tokens=128