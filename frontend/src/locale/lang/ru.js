export default {
  dashboard: 'Главная',
  configuration: 'Конфигурация',
  model_manager: 'Управление моделями',
  chat: 'Чат',
  page404: 'Страница не найдена',
  goBack: 'Вернуться на главную',
  bot: 'Бот',
  status: 'Статус',
  flags: 'Флаги',
  started: 'запущен',
  stopped: 'остановлен',
  can_join_groups: 'этот бот может быть добавлен в групповые чаты',
  cannot_join_groups: 'этого бота нельзя добавить в групповые чаты, поменяйте конфигурацию у BotFather',
  can_read_all: 'этому боты доступны все сообщения в групповых чатах',
  cannot_read_all: 'этому боту недоступны все сообщения в чатах, его можно активировать командами и ответами',
  access_mode: 'Режим ограничения доступа',
  main_active_modules: 'Активные модули (время загрузки)',
  uptime: 'Время работы',
  seconds: 'секунд',
  total_messages: 'Всего сообщений',
  total: 'ВСЕГО',
  consumed: 'ИСПОЛЬЗУЕТСЯ',
  process: 'ПРОЦЕСС',
  cache: 'Кэш',
  cache_size: 'Примерный размер при инициализации',
  processing: 'ожидание ответа',
  chat_offline: 'Пожалуйста, запустите бота, чтобы ему написать',
  empty_message: 'Текст сообщения',
  mmanager_offline: 'Пожалуйста, запустите бота, чтобы управлять моделями.',
  recommended_models: 'Рекомендованные модели',
  installed_models: 'Установленные модели',
  model_manager_header: 'Выберете категорию',
  install_model: 'Установить модель',
  name: 'Имя',
  voice: 'Голос',
  repo: 'Репозиторий',
  path: 'Путь',
  size: 'Размер (GB)',
  model_selected: 'Выбрать',
  are_you_sure: 'Точно?',
  confirm_uninstall: 'Пожалуйста подтвердите удаление в терминале',
  install: 'Установить',
  uninstall: 'Удалить',
  model_type: 'Тип модели',
  quant: 'Квантизация',
  base_voice: 'Голос для переозвучивания',
  confirm_install: 'Пожалуйста подтвердите установку в терминале!',
  no_base_voice: 'Голос переозвучивания требуется для voice-to-voice моделей',
  wrong_repo_format: 'Некорректный формат репозитория',
  model_installed: '✅ Модель установлена!',
  model_selected_ok: '✅ Модель выбрана, для её использования потребуется перезапуск',
  hf_repo: 'HuggingFace репозиторий',
  repo_path: 'Путь к файлу в репозитории',
  install_path: 'Путь папки для установки',
  model_filename: 'Имя файла модели',
  running: 'запущен',
  initializing: 'запуск',
  stopping: 'остановка',
  // config
  adminlist: 'Список id администраторов бота, имеющих доступ к административным командам',
  whitelist: 'Список id чатов и пользователей, которым разрешено вызывать бота',
  blacklist: 'Список id чатов и пользователей, которым запрещено вызывать бота',
  ignore_mode: 'Режим проверки списков доступа. В режиме белого списка доступ к боту разрешен только пользователям из белого списка. В режиме черного списка, пользователи из черного списка не могут вызывать бота. Когда оба режима активны, разрешены только чаты из белого списка, а пользователи из черного списка в них игнорируются.',
  active_modules: 'Укажите, какие модули бота вы хотите использовать',
  threaded_initialization: 'Когда включено, каждый модуль (и другие компоненты) загружаются параллельно',
  tts_path: 'Путь к каталогу моделей Coqui TTS, на данный момент были протестированы только модели VITS.',
  tts_voices: 'Список конфигурации с голосами Coqui TTS',
  tts_mode: 'В local режиме TTS запускается в процессе бота, в remote режиме делается запрос API к удаленному серверу и передаётся файл, в режиме localhttp он действует только как remote, но передаёт только путь вместо всего файла.',
  tts_replacements: 'Список строк, которые будут заменены перед передачей провайдеру TTS. Если что-то звучит не так, попробуйте исправить это заменой строки!',
  tts_credits: 'Текст, который передается команде справки и упоминает тех кто обучил и опубликовал модели tts',
  tts_ffmpeg_path: 'Путь к исполняемому файлу ffmpeg, который будет использоваться для преобразования аудио в голосовые сообщения',
  tts_enable_backends: 'Список различных Text-to-Speech бэкендов, каждый с собственными голосами.',
  tts_list_system_voices: 'Некоторые голоса нужны только как основа для переозвучки. Когда этот параметр отключен, в справке перечислены только несистемные голоса',
  tts_so_vits_svc_4_0_code_path: 'Путь к каталогу с кодом so-vits-svc версии 4.0',
  tts_so_vits_svc_4_1_code_path: 'Путь к каталогу с кодом so-vits-svc версии 4.1',
  tts_so_vits_svc_voices: 'Конфигурационный список с каждым голосом для so-vits-svc',
  tts_queue_size_per_user: 'Лимит запросов команд для TTS',
  tts_host: 'URL для сервера TTS API (servers/tts_server.py)',
  sd_host: 'URL для сервера API AUTOMATIC1111/stable-diffusion-webui',
  sd_max_steps: 'Максимальное количество шагов',
  sd_max_resolution: 'Максимальное разрешение',
  sd_available_samplers: 'Какие сэмплеры разрешены',
  sd_extra_prompt: 'Обертка для вводимого в prompt текста, используемая с командами /tti и /iti, чтобы запустить SD без оболочки для подсказок, используйте /ttiraw /itiraw',
  sd_extra_negative_prompt: 'Обёртка для вводимого в negative prompt текста',
  sd_default_sampler: 'Сэмплер по умолчанию в tti',
  sd_default_n_iter: 'Сколько изображений нужно сгенерировать',
  sd_default_width: 'Ширина по умолчанию',
  sd_default_height: 'Высота по умолчанию',
  sd_default_tti_steps: 'Количество шагов по умолчанию в tti',
  sd_default_tti_cfg_scale: 'Значение параметра classifier-free guidance для text-to-image',
  sd_default_iti_cfg_scale: 'Значение параметра classifier-free guidance для image-to-image',
  sd_default_iti_steps: 'Количество шагов по умолчанию в iti',
  sd_default_iti_denoising_strength: 'На сколько следует применять denoising для операций iti',
  sd_default_iti_sampler: 'Сэмплер по умолчанию в iti',
  sd_launch_process_automatically: 'Автоматически запускать процесс stable diffusion webui по необходимости',
  sd_launch_command: 'Команда для запуска stable diffusion webui',
  sd_launch_dir: 'Путь к каталогу stable diffusion webui (папка)',
  sd_launch_waittime: 'Время ожидания в секундах после запуска подпроцесса',
  sd_lora_custom_activations: 'Список пользовательских ключевых слов для моделей Lora в формате "слово": "<lora:имя_лоры:0.8> активатор"',
  sd_only_admins_can_change_models: 'Разрешить только администраторам бота менять модели',
  sd_queue_size_per_user: 'Сколько изображений может запросить пользователь для генерации, прежде чем достигнет лимит очереди',
  llm_host: 'URL API-сервера, такого как oobabooga/text-generation-webui API, kobold.cpp или сервер llama.cpp',
  llm_queue_size_per_user: 'Лимит очереди запросов LLM',
  llm_backend: 'Движок для работы с большими языковыми моделями',
  llm_python_model_type: 'Тип модели загружаемой через pytorch/transformers',
  llm_paths: 'Список ключ-значение конфигурации компонентов языковых моделей, таких как код, веса, лоры, адаптеры. Обычно нужно менять только те параметры, которые связаны с выбранным бэкэндом LLM.',
  llm_character: 'Файл персонажа, содержащий код для форматирование запроса для конкретной модели и описание персонажа для ролеплея',
  llm_history_grouping: 'Может быть "user" для сохранения истории отдельно с каждым пользователем или "chat" для сохранения истории группового чата со всеми пользователями в этом чате.',
  llm_max_history_items: 'Сколько сообщений хранится в истории с пользователем (принцип скользящего окна).',
  llm_generation_cfg_override: '',
  llm_assistant_cfg_override: '',
  llm_assistant_chronicler: 'llm_assistant_chronicler использует формат alpaca chronicler для вопросов и ответов, а также пользовательские форматы, указанные в файлах персонажей. raw формат необходим только для бэкэнда mlc.',
  llm_assistant_use_in_chat_mode: 'Вместо формирования истории разговора с помощью скользящего окна, всегда использовать формат promptа, указанный в файле персонажа, для instruct-only моделей.',
  llm_assistant_add_reply_context: 'Позволяет добавить 1-шаговую память для ответа на сообщения с вопросами и ответами.',
  llm_force_assistant_for_unsupported_models: 'Для не-instruct моделей разрешить использование ассистента (реализация будет переделана).',
  llm_max_tokens: 'Макс. новых токенов в режиме чата (скользящего окна).',
  llm_max_assistant_tokens: 'Макс. количество новых токенов в режиме ассистента (/ask).',
  llm_lcpp_gpu_layers: 'Количество слоев GPU в Llama.cpp.',
  llm_lcpp_max_context_size: 'Лимит контекста Llama.cpp.',
  llm_remote_launch_process_automatically: 'Запускать автоматически сервер LLM API (когда backend remote) по необходимости в дочернем процессе.',
  llm_remote_launch_command: 'Команда для запуска LLM-сервера.',
  llm_remote_launch_dir: 'Путь к каталогу, в котором будет выполнена команда.',
  llm_remote_launch_waittime: 'Сколько секунд ждать после запуска дочернего процесса сервера LLM API.',
  llm_remote_model_name: 'Имя файла модели, которое будет передаваться удаленному api серверу (если он поддерживает это).',
  stt_backend: 'Движок распознавания речи (Speech-to-text).',
  stt_model_path_or_name: 'Путь или имя модели распознавания речи (Speech-to-text).',
  stt_autoreply_mode: '',
  stt_autoreply_voice: '',
  stt_queue_size_per_user: '',
  tta_queue_size_per_user: '',
  tta_device: 'Где запускать модель генерации аудио из текста (Text-To-Audio).',
  tta_music_model: 'Путь или имя модели музыкального TTA.',
  tta_sfx_model: 'Путь или имя модели звуковых эффектов TTA.',
  tta_duration: 'Длительность сгенерированного аудио.',
  python_command: 'Команда Python (в настоящее время используется для запуска обработки аудио в аудио для службы so vits svc).',
  mm_preload_models_on_start: 'Если включено, модели будут предварительно загружены при запуске бота, в противном случае инициализация произойдёт по необходимости.',
  mm_ram_cached_model_count_limit: 'Сколько моделей может быть загружено в оперативной памяти одновременно.',
  mm_vram_cached_model_count_limit: 'Сколько моделей может быть загружено в VRAM одновременно.',
  mm_management_policy: 'В режиме COUNT только после достижения лимита модель будет выгружена, в режиме MEMORY, когда почти нет свободной памяти, модель будет выгружена (но невозможно оценить расход памяти для новой загружаемой модели).',
  mm_unload_order_policy: 'Какая модель должна быть выгружена первой при достижении лимита.',
  mm_autounload_after_seconds: 'Через сколько секунд неактивности модель должна быть помечена для выгрузки.',
  sys_webui_host: '',
  sys_api_host: '',
  sys_request_timeout: 'Таймаут запроса, влияет на запросы браузера, когда вы хотите общаться с моделью в веб-интерфейсе.',
  sys_api_log_level: 'Полезно для отладки.'
}
